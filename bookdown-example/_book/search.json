[{"path":"index.html","id":"rap-workshop","chapter":"1 RAP Workshop","heading":"1 RAP Workshop","text":"document contains examples exercises DHSC Data Science RAP Workshop R. take basic data analysis example can apply RAP template .","code":""},{"path":"downloading-data.html","id":"downloading-data","chapter":"2 Downloading data","heading":"2 Downloading data","text":"page take steps downloading data URL specified within config file, catching/logging errors encountered. perform following steps:download meta data describing ONS data availabledownload meta data get URL latest release chosen ONS datadownload latest release file.extract summary statistics print console.","code":""},{"path":"downloading-data.html","id":"data-setup-and-load-ons-meta-data","chapter":"2 Downloading data","heading":"2.1 Data setup and load ONS meta data","text":"start reading required libraries:good practice define parameters needed code configuration files, means don’t touch code need change parameter values.DHSC Template, main configuration file sits ./input directory called config.yml.config file exercise contains following parameter/settings:first step, made desired changes parameter values, load contents config.yml file. done follows:noted reading config file normally done top level main function, passes reference file functions need . instance loaded config file , illustrate can done.","code":"library(tidyverse)\nlibrary(httr)\nlibrary(dplyr)\nlibrary(jsonlite)data_dictionary_url: \"https://api.beta.ons.gov.uk/v1/datasets\"\ndata_id: \"regional-gdp-by-year\"\ninput_dir: ./input\noutput_dir: ./output# read in configuration\nconfig_path <- file.path(\"input\", \"config.yml\")\nconfig <- yaml::read_yaml(config_path)\n\n# print the config file details\nprint(config)"},{"path":"downloading-data.html","id":"get-a-list-of-data-that-can-be-extracted-using-this-ons-api","chapter":"2 Downloading data","heading":"2.2 Get a list of data that can be extracted using this ONS API","text":"pass data_dictionary_url GET function download list available data, wrangle writing .csv.","code":""},{"path":"downloading-data.html","id":"error-processing","chapter":"2 Downloading data","heading":"2.2.1 error processing","text":"use tryCatch({ … }) capture errors reading URL (reading files Input/Output). tryCatch block, encountering error, code automatically stops executing passes error function called . carries chain calling functions error either captured tryCatch block whole program fails, error written console. using tryCatch({…}) can intercept process, fine grained control deal error:can add addition information error message help users narrow problem lieswe can choose carry executing code error isn’t catastrophic.Normal usage wrap call get /O tryCatch {} block deal error error function. case just print message console later exercises see error messages can written output log.data dictionary contents shown belowdata dictionary","code":"  path <- config$data_dictionary_url\n\n  ret_code <- -1\n  tryCatch(\n    {\n      request <- GET(url = path) # see httr for more detail on this function\n      ret_code <- 0\n      },\n    error = function(e){\n      print(e)\n      message(e)\n      }\n    )\n\n  #check if an error reading, and if so return to calling function\n  if(ret_code < 0) return(NULL)\n\n  content <- rawToChar(request$content)\n  content_flat <- fromJSON(content, flatten = TRUE) # use this jsonlite function to convert JSON data to an R object\n  \n  # create a dataframe with the downloaded data dictionary and save to csv\n  # so I can see what data is available\n  df <- data.frame(id = content_flat$items$id,\n                   title = content_flat$items$title,\n                   release_frequency = content_flat$items$release_frequency,\n                   next_release = content_flat$items$next_release,\n                   description = content_flat$items$description,\n                   links_latest_versions = content_flat$items$links.latest_version.href,\n                   links_self_href= content_flat$items$links.self.href,\n                   qmi_href= content_flat$items$qmi.href)\n                   \n  print(df)\n\n  # now write the data to an output file so you can check the data dictionary offline. Note how the \n  # output directory is a parameter in the config file.\n  write.csv(df,\n            paste0(config$output_dir, \"/ons_api.csv\"))"},{"path":"downloading-data.html","id":"get-the-url-for-the-latest-release-of-a-specified-ons-file","chapter":"2 Downloading data","heading":"2.3 Get the URL for the latest release of a specified ONS file","text":"ONS data files unique identifier can used extract data. id interested specified config file use interrogate data dictionary. particular, want extract latest version, url can extracted data dictionary -> links_latest_versions field","code":"file_latest_version <- df %>%\n    filter(id == config$data_id) %>%\n    select(links_latest_versions) %>%\n    pull()\n\n  # Using the links_latest_versions we can get the meta data for the latest file\n  # and this meta data includes the url for the latest file in either csv or xlsx\n  # format. We choose .csv here -> extract it from downloads$csv$href\n\n  ret_code <- -1\n  tryCatch(\n    {\n      request <- GET(url = file_latest_version)\n      ret_code <- 0\n    },\n    error = function(e){\n      print(e)\n      message(e)\n    }\n  )\n\n  #check if an error reading, and if so return to calling function\n  if(ret_code < 0) return(NULL)\n\n  content <- rawToChar(request$content)\n  content_flat <- fromJSON(content, flatten=TRUE)\n  file_url <- content_flat$downloads$csv$href"},{"path":"downloading-data.html","id":"now-we-have-the-file-url-we-can-read-it-like-any-other-file","chapter":"2 Downloading data","heading":"2.4 Now we have the file url we can read it like any other file","text":"","code":"ret_code <- -1\n  tryCatch(\n    {\n      df_data <- read.csv(file_url)\n      ret_code <- 0\n    },\n    error = function(e){\n      print(e)\n      message(e)\n    }\n  )\n\n  #check if an error reading, and if so return to calling function\n  if(ret_code < 0) return(NULL)\n\n  write.csv(df_data,\n            paste0(config$output_dir,\n                   \"/\",\n                   config$data_id,\n                   \".csv\")\n  )"},{"path":"downloading-data.html","id":"print-summary-stats-and-finish","chapter":"2 Downloading data","heading":"2.5 Print summary stats and finish","text":"Note return statement commented , normal circumstances return file contents dataframe.next section, ’ll use techniques perform analysis different dataset, take generate RAP project.","code":" rowcount <- nrow(df_data)\n  log_message <- sprintf(\"Number of rows downloaded for %s was: %d\",\n                         config$data_id,\n                         rowcount)\n\n  print(log_message)\n  # return(df_data) "},{"path":"exercise.html","id":"exercise","chapter":"3 Exercise","heading":"3 Exercise","text":"section, ’ll perform analysis new dataset, can taken forward use RAP project.Please complete following tasks:Update data_id paramter config.yml: look data dictionary choose data_id wantUpdate data_id paramter config.yml: look data dictionary choose data_id wantGet url latest version file chosen data_idGet url latest version file chosen data_idDownload fileDownload fileProduce summary stats write file .csv output folder.Produce summary stats write file .csv output folder.5 Test error processing works adding nonsense URL, either config file, add code","code":""},{"path":"exercise-solution.html","id":"exercise-solution","chapter":"4 Exercise solution","heading":"4 Exercise solution","text":"","code":""},{"path":"exercise-solution.html","id":"calling-function","chapter":"4 Exercise solution","heading":"4.1 Calling function","text":"assumes download_data script invoked main function passed reference contents config.yml file. also assumes return either NULL data calling function.","code":"# read in configuration\nconfig_path <- file.path(\"input\", \"config.yml\")\nconfig <- yaml::read_yaml(config_path)\n\n#run functions to pull in and analyse data\ndf <- download_ons_data(config)\n\nif (is.na(df)) \n  print(\"oh dear\")\n  \n# do something with the data ...."},{"path":"exercise-solution.html","id":"download-code","chapter":"4 Exercise solution","heading":"4.2 Download Code","text":"","code":"# Load required packages --------------------------------------------------\nlibrary(tidyverse)\nlibrary(httr)\nlibrary(dplyr)\nlibrary(jsonlite)\n\n\n# Function definitions ----------------------------------------------------\n#' Download ONS data - retrieves ONS data using the ID specified in the config file\n#'\n#' @param config - contains I/O directory structure, ONS url and id for desired data\n#'\n#' @return ons_data as a dataframe\ndownload_ons_data <- function(config) {\n\n  # First I want to get a list of data made available via ONS API\n  # - the URL for this dictionary is specified in the config file.\n  # This isn't strictly needed for the exercise but it gives participants an\n  # idea of the types of data available, so they can choose which dataset they\n  # want to download\n  \n  path <- config$data_dictionary_url\n\n  ret_code <- -1\n  tryCatch(\n    {\n      request <- GET(url = path)\n      ret_code <- 0\n      },\n    error = function(e){\n      print(e)\n      message(e)\n      }\n    )\n\n  #check if an error reading, and if so return to calling function\n  if(ret_code < 0) return(NULL)\n\n  content <- rawToChar(request$content)\n  content_flat <- fromJSON(content, flatten = TRUE)\n\n  # create a dataframe with the downloaded data dictionary and save to csv\n  # so I can see what data is available\n  df <- data.frame(id = content_flat$items$id,\n                   title = content_flat$items$title,\n                   release_frequency = content_flat$items$release_frequency,\n                   next_release = content_flat$items$next_release,\n                   description = content_flat$items$description,\n                   links_latest_versions = content_flat$items$links.latest_version.href,\n                   links_self_href= content_flat$items$links.self.href,\n                   qmi_href= content_flat$items$qmi.href)\n                   \n  # ONS data files have a unique identifier and this can be used to extract the\n  # data. The id we are interested in is specified in the config file and so use\n  # that to interrogate the data dictionary. In particular, we want to\n  # extract the latest version, the url for which can be extracted from the\n  # data dictionary - use the links_latest_versions field\n  file_latest_version <- df %>%\n    filter(id == config$data_id) %>%\n    select(links_latest_versions) %>%\n    pull()\n\n  # Using the links_latest_versions we can get the meta data for the latest file\n  # and this meta data includes the url for the latest file in either csv or xlsx\n  # format. We choose .csv here -> extract it from downloads$csv$href\n\n  ret_code <- -1\n  tryCatch(\n    {\n      request <- GET(url = file_latest_version)\n      ret_code <- 0\n    },\n    error = function(e){\n      print(e)\n      message(e)\n    }\n  )\n\n  #check if an error reading, and if so return to calling function\n  if(ret_code < 0) return(NULL)\n\n  content <- rawToChar(request$content)\n  content_flat <- fromJSON(content, flatten=TRUE)\n  file_url <- content_flat$downloads$csv$href\n\n  # Now we have the file url we can read it like any other file\n  ret_code <- -1\n  tryCatch(\n    {\n      df_data <- read.csv(file_url)\n      ret_code <- 0\n    },\n    error = function(e){\n      print(e)\n      message(e)\n    }\n  )\n\n  #check if an error reading, and if so return to calling function\n  if(ret_code < 0) return(NULL)\n\n  write.csv(df_data,\n            paste0(config$output_dir,\n                   \"/\",\n                   config$data_id,\n                   \".csv\")\n  )\n\n  # print some basic data about the file e.g. row count and return the file\n  # to the calling function.\n  rowcount <- nrow(df_data)\n  log_message <- sprintf(\"Number of rows downloaded for %s was: %d\",\n                         config$data_id,\n                         rowcount)\n\n  print(log_message)\n  return(df_data)\n}\n"},{"path":"plotting-and-calculating-summary-statistics.html","id":"plotting-and-calculating-summary-statistics","chapter":"5 Plotting and calculating summary statistics","heading":"5 Plotting and calculating summary statistics","text":"page take steps data analysis wish . comprise manipulating plotting data generating statistics.","code":""},{"path":"plotting-and-calculating-summary-statistics.html","id":"reading-in-the-data","chapter":"5 Plotting and calculating summary statistics","heading":"5.1 Reading in the data","text":"start reading two libraries:First, can print column names dataset unique industry types dataset.","code":"library(dplyr)\nlibrary(readr)# print columns\nprint(colnames(df))\n\n# print industry types\nprint(unique(df$UnofficialStandardIndustrialClassification))"},{"path":"plotting-and-calculating-summary-statistics.html","id":"filtering-data","chapter":"5 Plotting and calculating summary statistics","heading":"5.2 Filtering data","text":"now clean data filter data health social care industry England type growth rate wish analyse.can set year column number allow plotting data straightforward. Note, “v4_1” column values look plot later.cleaned dataset, can save csv future use.","code":"# remove NAs, filter by industry, geography and growth rate figure\nhealth_gdp_time_series <- df %>%\n  filter(!is.na(v4_1)) %>%\n  filter(UnofficialStandardIndustrialClassification == \"Q: Human health and social work activities\") %>%\n  filter(Geography == \"England\") %>%\n  filter(GrowthRate == \"Annual growth rate\")# set year as a number and sort by\nhealth_gdp_time_series_sorted <- health_gdp_time_series %>%\n  mutate(Time = as.numeric(Time)) %>%\n  arrange(Time)# save data to csv\nwrite_csv(\n  health_gdp_time_series_sorted,\n  file = \"./output/health_gdp_time_series_sorted.csv\")"},{"path":"plotting-and-calculating-summary-statistics.html","id":"plotting-data","chapter":"5 Plotting and calculating summary statistics","heading":"5.3 Plotting data","text":"Now plot data using ggplot2.read ggplot2:set plot - reading DHSC colours, plotting line values set chart labels.save plotIt look like :alt text","code":"library(ggplot2)# plot\n\nggplot(data = df,\n       aes(Time,\n           v4_1,\n           colour = UnofficialStandardIndustrialClassification)) +\n  DHSCcolours::theme_dhsc() +\n  geom_line(linewidth = 1) +\n  geom_point(size = 3) +\n  theme(legend.position=\"none\") +\n  DHSCcolours::scale_colour_dhsc_d() +\n  labs(\n    title = \"Annual growth rate of Human health and social work activities, England\",\n    subtitle = \"2023-2021\",\n    x = \"Year\",\n    y = \"Annual growth rate (%)\") +\n  scale_x_continuous(breaks=seq(2013,2021,1))# save the plot\nggsave(\"./output/health_gdp_chart.svg\",\n         height = 5,\n         width = 10,\n         units=\"in\",\n         dpi=300)"},{"path":"plotting-and-calculating-summary-statistics.html","id":"generating-summary-stats","chapter":"5 Plotting and calculating summary statistics","heading":"5.4 Generating summary stats","text":"Finally, generate summary statistics dataset.calculate various stats:want filter dataset maximum minimum values find year occurred.start creating list now already defined variables maximum minimum mapped string, can print output .e. set max value string “maximum”.loop values, retrieve numerical value, filter dataset pull year figures . print values along average already calculated.gives us basic information dataset.next section, ’ll use techniques perform analysis different dataset, take generate RAP project.","code":"library(dplyr)# get stats\n\nminimum <- min(df$v4_1)\nmaximum <- max(df$v4_1)\naverage <- mean(df$v4_1)stats = list(\"minimum\" = minimum,\n             \"maximum\"= maximum)\n\n# get week values for stats, print\n\nfor (name in names(stats)) {\n  stat_value = stats[[name]]\n\n  year_val <- df %>%\n    filter(v4_1 == stats[[name]]) %>%\n    select(Time) %>%\n    pull\n\n  print(paste(\"the \",name, \"value is\", stat_value, \"(year:\", year_val, \")\"))\n}\n\nprint(paste(\"the average value is\",round(average,1)))"},{"path":"exercise-1.html","id":"exercise-1","chapter":"6 Exercise","heading":"6 Exercise","text":"section, ’ll perform analysis new dataset, can taken forward use RAP project.Please complete following tasks:Download clean ONS data Information communication activities annual GDP growth rate England.Download clean ONS data Information communication activities annual GDP growth rate England.Plot time series chart annual growth rate, using DHSC colours.Plot time series chart annual growth rate, using DHSC colours.Establish years lowest highest GDP growth rate values respectively dataset.Establish years lowest highest GDP growth rate values respectively dataset.Calculate mean GDP growth rate value dataset.Calculate mean GDP growth rate value dataset.","code":""},{"path":"exercise-solution-1.html","id":"exercise-solution-1","chapter":"7 Exercise solution","heading":"7 Exercise solution","text":"Minimum: -1.4% (2020)Maximum: 12.5% (2018)Average: 7.4%alt text","code":""},{"path":"exercise-solution-1.html","id":"code","chapter":"7 Exercise solution","heading":"7.1 Code","text":"Data filtering script:Plotting:Summary stats:","code":"library(dplyr)\nlibrary(readr)\n\nfilter_data <- function(df){\n\n  # print columns\n  print(colnames(df))\n\n  # print industry types\n  print(unique(df$UnofficialStandardIndustrialClassification))\n\n  # remove NAs, filter by industry, geography and growth rate figure\n  health_gdp_time_series <- df %>%\n    filter(!is.na(v4_1)) %>%\n    filter(UnofficialStandardIndustrialClassification == \"J: Information and communication\") %>%\n    filter(Geography == \"England\") %>%\n    filter(GrowthRate == \"Annual growth rate\")\n\n  # set year as a number and sort by\n  health_gdp_time_series_sorted <- health_gdp_time_series %>%\n    mutate(Time = as.numeric(Time)) %>%\n    arrange(Time)\n\n  # save data to csv\n  write_csv(\n    health_gdp_time_series_sorted,\n    file = \"./output/info_gdp_time_series_sorted.csv\"\n  )\n\n}\nlibrary(ggplot2)\n\nplot_data <- function(df){\n\n  # plot\n\n  ggplot(data = df,\n         aes(Time,\n             v4_1,\n             colour = UnofficialStandardIndustrialClassification)) +\n    DHSCcolours::theme_dhsc() +\n    geom_line(linewidth = 1) +\n    geom_point(size = 3) +\n    theme(legend.position=\"none\") +\n    DHSCcolours::scale_colour_dhsc_d() +\n    labs(\n      title = \"Annual growth rate of Information and communication activities, England\",\n      subtitle = \"2023-2021\",\n      x = \"Year\",\n      y = \"Annual growth rate (%)\") +\n    scale_x_continuous(breaks=seq(2013,2021,1))\n\n  # save the plot\n  ggsave(\"./output/information_gdp_chart.svg\",\n           height = 5,\n           width = 10,\n           units=\"in\",\n           dpi=300)\n\n}\n\nlibrary(dplyr)\n\n#get summary stats\n\nsummary_stats <- function(df){\n\n  # get stats\n\n  minimum <- min(df$v4_1)\n  maximum <- max(df$v4_1)\n  average <- mean(df$v4_1)\n\n  stats = list(\"minimum\" = minimum,\n               \"maximum\"= maximum)\n\n  # get week values for stats, print\n\n  for (name in names(stats)) {\n    stat_value = stats[[name]]\n\n    year_val <- df %>%\n      filter(v4_1 == stats[[name]]) %>%\n      select(Time) %>%\n      pull\n\n    print(paste(\"the \",name, \"value is\", stat_value, \"(year:\", year_val, \")\"))\n  }\n\n  print(paste(\"the average value is\",round(average,1)))\n\n}"}]
